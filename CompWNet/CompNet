# Mostly just a testing zone roight now, will eventually have to good stuff.
# Status: This is the beginning of a complex U-Net. Code is written, but at the moment it returns 
# blank images. I'm not sure why. I'm also not sure if CompConv2D is written correctly conceptually. 
# June 3, 2022

# Imports
import os
from re import I
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
import tensorflow as tf
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
from tensorflow import keras as ks
from keras import layers
import cv2
import numpy as np
import matplotlib.pyplot as plt
import glob
from keras import backend as K
from keras.models import Model

# Variables
EPOCHS = 5
NUM_BRAINS = 2
TOTAL_PICS = 30
TEST_PICS = 5
BRAINS_ADDR = '/Users/duncan.boyd/Documents/WorkCode/workvenv/MRIPractice/Train/*.npy'
STATS_ADDR = '/Users/duncan.boyd/Documents/WorkCode/workvenv/WNetPractice/stats.npy'
MASK_ADDR = '/Users/duncan.boyd/Documents/WorkCode/workvenv/WNetPractice/sampling_mask.npy'

# Loss function
def nrmse(y_true, y_pred):
    denom = K.sqrt(K.mean(K.square(y_true), axis=(1,2,3)))
    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=(1,2,3)))\
    /denom

# IFFT layer, used in u_net.
def ifft_layer(kspace):
    real = layers.Lambda(lambda kspace : kspace[:,:,:,0])(kspace)
    imag = layers.Lambda(lambda kspace : kspace[:,:,:,1])(kspace)
    kspace_complex = tf.complex(real,imag)
    rec1 = tf.abs(tf.ifft2d(kspace_complex))
    rec1 = tf.expand_dims(rec1, -1)
    return rec1

# Loads MRIs to arrays. Returns reconstructed and deconstructed test and train data in both 
# kspace and image domain. Note that addresses are hard coded as variables. 
# Therefore, it only works on my (Duncan's) work computer. Data used is from https://drive.google.com/drive/folders/1wa4npKnob3YPwMjuXT_-9YQX9rua0OiE?usp=sharing
# Only 2 scans from test data is used, as this is quite small scale.
def get_brains():
    stats = np.load(STATS_ADDR)
    samp_mask = np.load(MASK_ADDR)

    imshape = (256,256)
    norm = np.sqrt(imshape[0]*imshape[1])

    brains = [] # Complete MRI images.
    non_brains = [] # Complete K space.
    knon_brains = [] # Undersampled K space.
    k_brains = [] # Undersampled MRI images

    count = 0
    for brain in glob.glob(BRAINS_ADDR) :
        count += 1
        kspace = np.load(brain)/norm
        kspace2 = kspace.copy()
        kspace3 = kspace.copy()
        kspace2[ :, samp_mask, : ] = 0
        kspace2 = (kspace2-stats[0])/stats[1]
        rec1 = np.abs(np.fft.ifft2(kspace[:,:,:,0]+1j*kspace[:,:,:,1])).astype(np.float64)
        rec2 = np.abs(np.fft.ifft2(kspace2[:,:,:,0]+1j*kspace2[:,:,:,1])).astype(np.float64)
        if rec1.shape == (170, 256, 256) :
            brains.append(rec1)
            non_brains.append(kspace2)
            knon_brains.append(kspace3)
            k_brains.append(rec2)
        if count == NUM_BRAINS :
            break

    brains = np.array(brains)
    print(brains.shape)
    non_brains = np.array(non_brains)
    print(non_brains.shape)
    knon_brains = np.array(knon_brains)
    print(knon_brains.shape)
    k_brains = np.array(k_brains)
    print(knon_brains.shape)

    brains = brains / np.amax(brains)
    brains = np.expand_dims(brains, axis=-1)
    train_set_rec = brains[0, 60:(60+TOTAL_PICS), :, :]
    train_set_dec = non_brains[0, 60:(60+TOTAL_PICS), :, :]
    train_set_half_rec = knon_brains[0, 60:(60+TOTAL_PICS), :, :]
    test_set_rec = brains[1, 80:(80+TEST_PICS), :, :]
    test_set_half_rec = k_brains[1, 80:(80+TEST_PICS), :, :]
    test_set_dec = non_brains[1, 80:(80+TEST_PICS), :, :]

    print("\nData in in range 0<x<1")
    print("Train rec: ", train_set_rec.shape)
    print("Train dec: ", train_set_dec.shape)
    print("Train half rec: ", train_set_half_rec.shape)
    print("Test rec: ", test_set_rec.shape)
    print("Test half rec: ", test_set_half_rec.shape)
    print("Test dec: ", test_set_dec.shape, "\n\n")

    return stats, train_set_rec, train_set_dec, train_set_half_rec, test_set_rec, test_set_half_rec, test_set_dec

# Custom complex convolution. Really loves returning blank images, I don't know why.
# Uses algerbra below. I've used "|" to denote a two channel array, and "f" to denote a variable that is a part of a filter.

# (R | I) * (Rf | If) = Or | Oi = (R * Rf - I * If) | (I * Rf + R * If)

class CompConv2D(layers.Layer):
    def __init__(self, out_channels, kshape=(3, 3)):
        super(CompConv2D, self).__init__()
        self.convreal = layers.Conv2D(out_channels, kshape, activation='relu', padding='same')
        self.convimag = layers.Conv2D(out_channels, kshape, activation='relu', padding='same')

    def call(self, input_tensor, training=False):
        ureal, uimag = tf.split(input_tensor, num_or_size_splits=2, axis=3)
        oreal = self.convreal(ureal) - self.convimag(uimag)
        oimag = self.convimag(ureal) + self.convreal(uimag)
        x = tf.concat([oreal, oimag], axis=3)
        return x

# U-Net model. Includes kspace domain U-Net and IFFT.
# Note: Filters are halved to maintain structure, but they probably shouldn't be. Although this may reduce performance, I think it's probably fine for testing.
# Question: Can a purely kspace model be trained, with no reference to image domain? For this code, I've assumed no (also just for convenience viewing results).
def u_net(mu1,sigma1,mu2,sigma2, H=256,W=256,channels = 2,kshape = (3,3)):
    inputs = layers.Input(shape=(H,W,channels))

    conv1 = CompConv2D(24)(inputs)
    conv1 = CompConv2D(24)(conv1)
    conv1 = CompConv2D(24)(conv1)
    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = CompConv2D(32)(pool1)
    conv2 = CompConv2D(32)(conv2)
    conv2 = CompConv2D(32)(conv2)
    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = CompConv2D(64)(pool2)
    conv3 = CompConv2D(64)(conv3)
    conv3 = CompConv2D(64)(conv3)
    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = CompConv2D(128)(pool3)
    conv4 = CompConv2D(128)(conv4)
    conv4 = CompConv2D(128)(conv4)
    
    up1 = layers.concatenate([layers.UpSampling2D(size=(2, 2))(conv4), conv3],axis=-1)
    conv5 = CompConv2D(64)(up1)
    conv5 = CompConv2D(64)(conv5)
    conv5 = CompConv2D(64)(conv5)
    
    up2 = layers.concatenate([layers.UpSampling2D(size=(2, 2))(conv5), conv2],axis=-1)
    conv6 = CompConv2D(32)(up2)
    conv6 = CompConv2D(32)(conv6)
    conv6 = CompConv2D(32)(conv6)
    
    up3 = layers.concatenate([layers.UpSampling2D(size=(2, 2))(conv6), conv1],axis=-1)
    conv7 = CompConv2D(24)(up3)
    conv7 = CompConv2D(24)(conv7)
    conv7 = CompConv2D(24)(conv7)

    conv8 = layers.Conv2D(2, (1, 1), activation='linear')(conv7)
    res1 = layers.Add()([conv8,inputs])
    res1_scaled = layers.Lambda(lambda res1 : (res1*sigma1+mu1))(res1)
    
    rec1 = layers.Lambda(ifft_layer)(res1_scaled)
    final = layers.Lambda(lambda rec1 : (rec1-mu2)/sigma2)(rec1)

    model = Model(inputs=inputs, outputs=final)
    return model

# Loads data. Apologies that they're out of order.
# train_set_rec -> Complete, image domain 
# train_set_dec -> Incomplete, kspace domain
# train_st_half_rec -> Complete, kspace domain
# test_set_rec -> Complete, image domain
# test_set_half_rec -> Complete, kspace domain MAY HAVE AN ERROR, BE CAREFUL. IS THE WRONG SHAPE
# test_set_dec -> Incomplete, kspace domain
stats, train_set_rec, train_set_dec, train_set_half_rec, test_set_rec, test_set_half_rec, test_set_dec = get_brains()

# Declare, compile, fit the model.
model = u_net(stats[0],stats[1],stats[2],stats[3])
model.compile(optimizer='adam', loss=nrmse)

# Fits model using training data.
model.fit(train_set_dec, train_set_rec, epochs=EPOCHS)
model.summary()

# Makes predictions
predictions = model.predict(test_set_dec)
print(predictions.shape)

# Displays predictions
plt.figure(figsize=(10,10))
plt.subplot(1,3,1)
plt.imshow((255.0 - test_set_rec[0]), cmap='Greys')
plt.subplot(1,3,2)
plt.imshow((255.0 - predictions[0]), cmap='Greys')
plt.show()


